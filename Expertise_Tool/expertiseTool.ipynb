{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "expertiseTool.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install flatten_json "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riDrLXeM1yy3",
        "outputId": "454b6e1a-b3d6-47a9-dd33-f1abe909aa5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flatten_json in /usr/local/lib/python3.7/dist-packages (0.1.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from flatten_json) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Do you know the number of levels Y/n\n",
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from flatten_json import flatten\n",
        "# Import the GaussianMixture class\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L6rc0Hdo1j1g"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def question_expertise_level():\n",
        "    value_of_k = 0\n",
        "    i = 0\n",
        "    while i < 2:\n",
        "        answer = input(\"Do you Know the Experise Level? (yes or no) \")\n",
        "        if any(answer.lower() == f for f in [\"yes\", 'y', '1', 'ye']):\n",
        "          # If yes we call the KMeans cluster method here\n",
        "            value_of_k = int(answer)\n",
        "            break\n",
        "\n",
        "        elif any(answer.lower() == f for f in ['no', 'n', '0']):\n",
        "          # if no we call the GMM Cluster Method here\n",
        "            value_of_k = 2\n",
        "            print(value_of_k)\n",
        "            break\n",
        "        else:\n",
        "            i += 1\n",
        "            if i < 2:\n",
        "                print('Please enter yes or no')\n",
        "            else:\n",
        "                print(\"Nothing done\")\n",
        "    return value_of_k  "
      ],
      "metadata": {
        "id": "irM7w4mG2iEq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "w-xwHq1A5VHr",
        "outputId": "d03569e8-5ddb-4987-c07b-d6500a4a04dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you know the number of dimensions of expertise you wish to consider?2\n",
            "Enter the dimensions of expertise as a comma separated list: Usage tensorflow,python java,css\n",
            "How many users will be considered for comparison in the clustering: Note minimum is 100 users200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8c0b3ffabe42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnewData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m \u001b[0mnewData_unflattned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_stack_exchange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;31m# cluster_method()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;31m#filter rows of original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-8c0b3ffabe42>\u001b[0m in \u001b[0;36mquery_stack_exchange\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# Handle the number of users to consider clustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mnumber_of_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"How many users will be considered for comparison in the clustering: Note minimum is 100 users\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_pages\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mnumber_of_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnumber_of_pages\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'str' and 'int'"
          ]
        }
      ],
      "source": [
        "\n",
        "# Either Python or Tensorflow ?\n",
        "#import the dataset for the TENSORFLOW tags from the STACKEXCHANGE API\n",
        "\n",
        "def query_stack_exchange():\n",
        "  # Ask for the hashtag numbers\n",
        "  number_of_hashtags = input(\"Do you know the number of dimensions of expertise you wish to consider?\")\n",
        "  # Ask for the hashtag Values\n",
        "  hashtag_values = input(\"Enter the dimensions of expertise as a comma separated list: Usage tensorflow,python \")\n",
        "  \n",
        "  # Handle the number of users to consider clustering\n",
        "  number_of_pages = input(\"How many users will be considered for comparison in the clustering: Note minimum is 100 users\")\n",
        "  if(number_of_pages > 100):\n",
        "    number_of_pages = (number_of_pages//100)\n",
        "  else:\n",
        "    #  number of pages being set to one is equivalent to 100 users\n",
        "    number_of_pages = 1 \n",
        "\n",
        "   \n",
        "  # # call the function which will ask the user if they know the expertise level or not\n",
        "  # value_of_k = question_expertise_level()\n",
        "\n",
        "  complete_data=[]\n",
        "  dfs = []\n",
        "  for i in range (int(number_of_pages)):\n",
        "    response = requests.get(\"https://api.stackexchange.com/2.3/search/advanced?order=desc&sort=activity&q=\" + str(hashtag_values) + \"&site=stackoverflow&filter=!*MZqiH2P51Zpclr2&pagesize=100&page=\" + str(i + 1))\n",
        "    newData =json.loads(response.text)\n",
        "    # newData = flatten(newData_unflatten)\n",
        "    # print(newData)\n",
        "    for item in newData[\"items\"]:\n",
        "        # item = flatten(item)\n",
        "        # print(item)\n",
        "        complete_data.append(item)\n",
        "        dfs.append(pd.DataFrame([item]))\n",
        "    print(\"Processed page \" + str(i + 1) + \", returned \" + str(response))\n",
        "    time.sleep(2) # timeout not to be rate-limited\n",
        "  df = pd.concat(dfs, ignore_index=True, sort=False)\n",
        "  print(df)\n",
        "  dataStackexchange = df.to_csv('dataStackExchange.csv', encoding='utf-8', index=False)\n",
        "  #import the dataset for the 150 Elements\n",
        "  dataset_path = \"dataStackExchange.csv\"\n",
        "  dataset = pd.read_csv(dataset_path)#, error_bad_lines=False)\n",
        "\n",
        "  # which will ask the user if they know the expertise level or not\n",
        "  answer = input(\"Do you have a defined number of expertise levels?  (yes or no) \")\n",
        "  # If yes we call the KMeans cluster method here\n",
        "  if any(answer.lower() == f for f in [\"yes\", 'y', '1', 'ye']): \n",
        "    value_of_k = int(answer)\n",
        "    # Fill missing values with mean column values in the data set\n",
        "    dataset.fillna(dataset.mean(), inplace=True)\n",
        "    #select the columns you wanna train your data with SET 2:[Upvotes, Downvotes]\n",
        "    X = df.loc[:, ['down_vote_count', 'up_vote_count']].values\n",
        "    # #Transform the data\n",
        "    # df = pca.fit_transform(X)\n",
        "    # when it is not-manual it is giving me an error \n",
        "    kmeans5 = KMeans(n_clusters = value_of_k)\n",
        "    y_kmeans5 = kmeans5.fit_predict(X)\n",
        "    print(y_kmeans5)\n",
        "    dataset['cluster'] = y_kmeans5\n",
        "    #Getting unique label\n",
        "    u_labels = np.unique(y_kmeans5)\n",
        "    print(u_labels)\n",
        "    #plotting the results:\n",
        " \n",
        "  # if no we call the GMM Cluster Method here\n",
        "  elif any(answer.lower() == f for f in ['no', 'n', '0']): \n",
        "    print(\"That's okay!\")\n",
        "    print(\"We will help you pick the best cluster number using Gaussian Mixture Model(GMM) which is a clustering algorithm\")\n",
        "    # df = pd.read_csv('usersCombined_TF.csv')\n",
        "    X = df.loc[:, ['down_vote_count', 'up_vote_count']].values\n",
        "    \n",
        "    # Set up a range of cluster numbers to try\n",
        "    n_range = range(2,11)\n",
        "\n",
        "    # Create empty lists to store the BIC and AIC values\n",
        "    bic_score = []\n",
        "    aic_score = []\n",
        "\n",
        "    # Loop through the range and fit a model\n",
        "    for n in n_range:\n",
        "      gm = GaussianMixture(n_components=n, \n",
        "                          random_state=123, \n",
        "                         n_init=10)\n",
        "      gm.fit(X)\n",
        "      # Append the BIC and AIC to the respective lists\n",
        "      bic_score.append(gm.bic(X))\n",
        "      aic_score.append(gm.aic(X))\n",
        "    # Plot the BIC and AIC values together\n",
        "    fig, ax = plt.subplots(figsize=(12,8),nrows=1)\n",
        "    ax.plot(n_range, bic_score, '-o', color='orange')\n",
        "    ax.plot(n_range, aic_score, '-o', color='green')\n",
        "    ax.set(xlabel='Number of Clusters', ylabel='Score')\n",
        "    ax.set_xticks(n_range)\n",
        "    ax.set_title('BIC and AIC Scores Per Number Of Clusters')\n",
        "    \n",
        "\n",
        "    print(\"HINT: CHOOSE THE MOST most appropriate cluster number by using the Cluster Value, after which the chart really levels off.\")\n",
        "    gmm_cluster_value = input(\"Enter the most appropriate cluster value based on the above chart values\")\n",
        "    X = df.loc[:, ['down_vote_count', 'up_vote_count']].values\n",
        "    gm = GaussianMixture(n_components= int(gmm_cluster_value), random_state=123, n_init=10)\n",
        "    preds = gm.fit_predict(X)\n",
        " \n",
        "  # # Fill missing values with mean column values in the data set\n",
        "  # dataset.fillna(dataset.mean(), inplace=True)\n",
        "  # #select the columns you wanna train your data with SET 2:[Upvotes, Downvotes]\n",
        "  # X = df.loc[:, ['down_vote_count', 'up_vote_count']].values\n",
        "  # # #Transform the data\n",
        "  # # df = pca.fit_transform(X)\n",
        "  # # when it is not-manual it is giving me an error \n",
        "  # kmeans5 = KMeans(n_clusters=2)\n",
        "  # y_kmeans5 = kmeans5.fit_predict(X)\n",
        "  # print(y_kmeans5)\n",
        "  # dataset['cluster'] = y_kmeans5\n",
        "  # #Getting unique label\n",
        "  # u_labels = np.unique(y_kmeans5)\n",
        "  # print(u_labels)\n",
        "  # #plotting the results:\n",
        " \n",
        "  # for i in u_labels:\n",
        "  plt.scatter(dataset.cluster == 0 , dataset.cluster == 1, label = i)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  dataset[dataset.cluster == 0].to_csv(\"set1_First_Cluster_Tensorflow.csv\")\n",
        "  dataset[dataset.cluster == 1].to_csv(\"set1_Second_Cluster_Tensorflow.csv\")\n",
        "  return newData\n",
        "\n",
        "newData_unflattned = query_stack_exchange()\n",
        "# cluster_method()\n",
        "#filter rows of original data\n",
        "# filtered_label0 = [dataset.cluster == 0]\n",
        " \n",
        "# filtered_label1 = [dataset.cluster == 1]\n",
        " \n",
        "# #Plotting the results\n",
        "# plt.scatter(filtered_label0[:,0] , filtered_label0[:,1] , color = 'red')\n",
        "# plt.scatter(filtered_label1[:,0] , filtered_label1[:,1] , color = 'black')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def query_user_id():\n",
        "\n",
        "  # newData_flattened = flatten(newData_unflattned)\n",
        "  dfs = []\n",
        "  for item in newData_unflattned[\"items\"]:\n",
        "     item = flatten(item)\n",
        "    #  print(item)\n",
        "     dfs.append(pd.DataFrame([item]))\n",
        "  df = pd.concat(dfs, ignore_index=True, sort=False)\n",
        "  dataStackexchange = df.to_csv('dataStackExchange.csv', encoding='utf-8', index=False)\n",
        "  #import the dataset for the 150 Elements\n",
        "  dataset_path = \"dataStackExchange.csv\"\n",
        "  dataset = pd.read_csv(dataset_path)#, error_bad_lines=False)\n",
        "  # Fill missing values with mean column values in the data set\n",
        "  dataset.fillna(dataset.mean(), inplace=True)\n",
        "  # convert values to int\n",
        "  dataset = dataset.astype({\"owner_account_id\":\"int\",\"owner_reputation\":\"int\", \"owner_user_id\": \"int\"})\n",
        "  #select the columns you wanna train your data with SET 2:[Upvotes, Downvotes]\n",
        "  X = df.loc[:, ['down_vote_count', 'up_vote_count']].values\n",
        "  # #Transform the data\n",
        "  # df = pca.fit_transform(X)\n",
        "  # when it is not-manual it is giving me an error \n",
        "  kmeans5 = KMeans(n_clusters=2)\n",
        "  y_kmeans5 = kmeans5.fit_predict(X)\n",
        "  print(y_kmeans5)\n",
        "  dataset['cluster'] = y_kmeans5   \n",
        "  # dataset = dataset.astype({\"owner_account_id\":\"int\",\"owner_reputation\":\"int\", \"owner_user_id\": \"int\"})\n",
        "  print(dataset)\n",
        "  user_id = input(\"Enter the is of the user you wish to query for: \")\n",
        "  # ddata = dataset.loc[(dataset['owner_user_id'] == user_id) & (dataset['cluster'] == 0)]\n",
        "  print(dataset.loc[dataset['cluster'] == 1]])\n",
        "  # if dataset[(dataset.owner_user_id == user_id) & (dataset.cluster == 0)].all():\n",
        "  #   print(\"Yes, USER ID found in Cluster 0\" )\n",
        "  # if dataset[(dataset.owner_user_id == user_id) & (dataset.cluster == 1)].all():\n",
        "  #   print(\"Yes, USER ID found in Cluster 1\" )\n",
        "  # else:\n",
        "  #   print(\"user is not in clustered data\")\n",
        "\n",
        "query_user_id()\n",
        "# # Kmeans clustering\n",
        "\n",
        "# # Output a percentage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saEUt9IGuuG5",
        "outputId": "c932130e-dc86-4c3f-db79-9bab5a7c6189"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "        tags_0        tags_1                  tags_2  owner_account_id  \\\n",
            "0       python    tensorflow        object-detection          15315560   \n",
            "1       python    tensorflow        machine-learning          11396232   \n",
            "2       python    python-3.x              tensorflow          23165717   \n",
            "3       python    tensorflow                     NaN          14742883   \n",
            "4       python    tensorflow        machine-learning          22181347   \n",
            "..         ...           ...                     ...               ...   \n",
            "95      python    tensorflow  tensorflow-probability          18206662   \n",
            "96      python    tensorflow                   keras          16824076   \n",
            "97      python    tensorflow                   keras          11230697   \n",
            "98      python        pandas                   numpy          14320442   \n",
            "99  tensorflow  installation            ubuntu-18.04          15821376   \n",
            "\n",
            "    owner_reputation  owner_user_id owner_user_type  \\\n",
            "0                  1       11049543      registered   \n",
            "1                130        8354548      registered   \n",
            "2                 21       17265696      registered   \n",
            "3                 85       10647086      registered   \n",
            "4                 55       16425016      registered   \n",
            "..               ...            ...             ...   \n",
            "95                 1       13249955      registered   \n",
            "96               560       13132428  does_not_exist   \n",
            "97                 3       19745408      registered   \n",
            "98               165       17779615      registered   \n",
            "99                11       11415628      registered   \n",
            "\n",
            "                                  owner_profile_image owner_display_name  \\\n",
            "0   https://lh6.googleusercontent.com/-mXC4_LC-D_M...     Syrine Mahmoud   \n",
            "1   https://www.gravatar.com/avatar/e95a6c8ae138d6...              Heems   \n",
            "2   https://lh3.googleusercontent.com/a/AATXAJyNiM...            Bisseys   \n",
            "3   https://www.gravatar.com/avatar/fab30f9d70233c...          Pysnek313   \n",
            "4   https://lh3.googleusercontent.com/a/AATXAJyYOW...         pasho_6798   \n",
            "..                                                ...                ...   \n",
            "95  https://www.gravatar.com/avatar/6ee1b046e53fc9...       TheGitPuller   \n",
            "96                                                NaN        user7089140   \n",
            "97  https://graph.facebook.com/10155530413828699/p...           Alex Moh   \n",
            "98  https://www.gravatar.com/avatar/5e194c20a31559...              Susan   \n",
            "99  https://lh3.googleusercontent.com/-QEhFag29GNA...   Francisco Ferraz   \n",
            "\n",
            "                                           owner_link  ...          tags_3  \\\n",
            "0   https://stackoverflow.com/users/11049543/syrin...  ...             NaN   \n",
            "1       https://stackoverflow.com/users/8354548/heems  ...           keras   \n",
            "2    https://stackoverflow.com/users/17265696/bisseys  ...             nlp   \n",
            "3   https://stackoverflow.com/users/10647086/pysne...  ...             NaN   \n",
            "4   https://stackoverflow.com/users/16425016/pasho...  ...           keras   \n",
            "..                                                ...  ...             ...   \n",
            "95  https://stackoverflow.com/users/13249955/thegi...  ...             NaN   \n",
            "96                                                NaN  ...  neural-network   \n",
            "97  https://stackoverflow.com/users/19745408/alex-moh  ...   deep-learning   \n",
            "98     https://stackoverflow.com/users/17779615/susan  ...      matplotlib   \n",
            "99  https://stackoverflow.com/users/11415628/franc...  ...          protoc   \n",
            "\n",
            "                      tags_4  bounty_amount  bounty_closes_date  \\\n",
            "0                        NaN      66.666667        1.661087e+09   \n",
            "1                        NaN      66.666667        1.661087e+09   \n",
            "2   huggingface-transformers      66.666667        1.661087e+09   \n",
            "3                        NaN      50.000000        1.661182e+09   \n",
            "4                        NaN      66.666667        1.661087e+09   \n",
            "..                       ...            ...                 ...   \n",
            "95                       NaN      66.666667        1.661087e+09   \n",
            "96                       NaN      66.666667        1.661087e+09   \n",
            "97                sequential      66.666667        1.661087e+09   \n",
            "98                     scipy      66.666667        1.661087e+09   \n",
            "99   tensorflow-model-garden      66.666667        1.661087e+09   \n",
            "\n",
            "    accepted_answer_id  owner_accept_rate   closed_date  closed_reason  \\\n",
            "0           70157126.5          56.909091  1.660510e+09            NaN   \n",
            "1           70157126.5          56.909091  1.660510e+09            NaN   \n",
            "2           70157126.5          56.909091  1.660510e+09            NaN   \n",
            "3           70157126.5          56.909091  1.660510e+09            NaN   \n",
            "4           68972284.0          56.909091  1.660510e+09            NaN   \n",
            "..                 ...                ...           ...            ...   \n",
            "95          70157126.5          56.909091  1.660510e+09            NaN   \n",
            "96          70157126.5          56.909091  1.660510e+09            NaN   \n",
            "97          73331877.0          56.909091  1.660510e+09            NaN   \n",
            "98          70157126.5          56.909091  1.660510e+09            NaN   \n",
            "99          70157126.5          56.909091  1.660510e+09            NaN   \n",
            "\n",
            "    protected_date  cluster  \n",
            "0     1.559347e+09        0  \n",
            "1     1.559347e+09        0  \n",
            "2     1.559347e+09        0  \n",
            "3     1.559347e+09        0  \n",
            "4     1.559347e+09        0  \n",
            "..             ...      ...  \n",
            "95    1.559347e+09        0  \n",
            "96    1.559347e+09        0  \n",
            "97    1.559347e+09        0  \n",
            "98    1.559347e+09        0  \n",
            "99    1.559347e+09        0  \n",
            "\n",
            "[100 rows x 32 columns]\n",
            "Enter the is of the user you wish to query for: 82736281\n",
            "      tags_0   tags_1            tags_2  owner_account_id  owner_reputation  \\\n",
            "55  anaconda  jupyter  jupyter-notebook           2796776              5739   \n",
            "\n",
            "    owner_user_id owner_user_type  \\\n",
            "55        2816194      registered   \n",
            "\n",
            "                                  owner_profile_image owner_display_name  \\\n",
            "55  https://www.gravatar.com/avatar/09bfafc81c973e...          user31039   \n",
            "\n",
            "                                           owner_link  ...  tags_3  tags_4  \\\n",
            "55  https://stackoverflow.com/users/2816194/user31039  ...   conda     NaN   \n",
            "\n",
            "    bounty_amount  bounty_closes_date  accepted_answer_id  owner_accept_rate  \\\n",
            "55      66.666667        1.661087e+09          70157126.5               80.0   \n",
            "\n",
            "     closed_date  closed_reason  protected_date  cluster  \n",
            "55  1.660510e+09            NaN    1.559347e+09        1  \n",
            "\n",
            "[1 rows x 32 columns]\n"
          ]
        }
      ]
    }
  ]
}